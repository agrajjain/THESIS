\chapter{Conclusion}
\label{cha:conclusion}
This thesis presented an implementation of Simultaneous Localization and Mapping on the Integrated Mobile Platform. A general overview of EKF and its application to SLAM was given. The Integrated Mobile Platform, a differential drive platform with capabilities of real-time implementation of SLAM was designed and built. The platform was equipped with encoders for odometry, a LIDAR and a camera for environmental sensing. A multi level system architecture was set up. The motion models for the platform and how they are used in EKF was discussed. Two kinds of features were detected from the LIDAR data: 1) Point features which consisted of cylinder like objects placed in the arena, and 2) A linear feature extractor which was used to reconstruct the walls of the arena. A simplistic algorithm for point features was shown to be not robust enough to be used in a real world applications. Modifications to the algorithms were proposed. For linear features, two algorithms were discussed, one based on RANSAC and one based on Hough transform. The Hough transform based algorithm was shown to be robust even to humans moving through the environment. Both the linear and point features were utilized in the SLAM algorithm and results were presented. The reconstructed paths were analyzed to obtain intuition about the process. It was seen that in a controlled environment, the combination of point features and linear features give the least error. In an uncontrolled environment with people moving across the field of view of the LIDAR, only the Hough transform is robust enough to be used and it is seen to reconstruct the path with reasonable accuracy. 


Further work can include more robust feature extraction for point features by utilizing the optimized functions of OpenCV. Robust feature extractors such as sift or surf should also be considered and experimented with. Also in this thesis the on-board camera available on the platform was not utilized. Further work on analyzing the images acquired by the on-board camera can result in augmenting encoder based odometry by visual odometry. With visual odometry, the SLAM implementation will not be dependent on the robot having encoders and can be used for a variety of platforms. Since the platform is equipped with a real time arm processor, implementing the current SLAM algorithm in real-time will provide more insight about the different feature extractors discussed in terms of their speed and processing power requirements. The computational power on the platform is capable of running more complex autonomous navigation algorithms. The maps obtained by SLAM can be used as a starting point for algorithms such as path planning. Lastly,sensor fusion for LIDAR and camera to detect and discern features togrther are an important area of future work.
