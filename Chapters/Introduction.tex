\chapter{Introduction}

	
	% The problem of Simultaneous Localization and Mapping or SLAM has occupied a large part of research in robotics. SLAM addresses the problem of a robot moving through a previously unknown environment. The robot makes relative observations of it's self-perception and of the environment, both of which have some component of noise. To reconstruct a map of the environment and the path taken by the robot is the primary goal of SLAM. SLAM is a key requirement for any truly autonomous robot.
	% If an accurate map of the environment was already available, estimating the path of the robot would be a simple localization task\cite{Thrun1999}. Similarly if the true path of the robot was known, building a map of the environment is straightforward\cite{Tripathi2014}\cite{lakemeyer2003}. However when both are unknown the problem is challenging. 
	
	% SLAM is extremely useful for mobile robots traveling in unknown surroundings. It lets mobile robots to help in exploration by going places that are too distant\cite{Golombek05121997} or dangerous\cite{Thrun2003}. Especially robots that need to operate in extreme environments such as undersea, underground or on other planets, they must be capable of SLAM. Even in simple environments such as the inside of a building accurate prior maps are difficult to find and the robot has to construct one of it's own. 
	% The maps produced by SLAM can either be used on their own like done in \cite{Arbeiter2010} or \cite{Thrun2003} where SLAM is used to map tunnel systems.Or more typically serve as starting points for motion planning or autonomous navigation\cite{pp1,pp2,pp3,pp4,pp5,pp6}.
	
	% The cyclical nature of the relationship between localization and mapping is a result of how errors in the sensors readings are corrupted by error in robot's motion estimate. As the robot moves, the estimate of it's pose is corrupted by motion noise. The estimate of the environment objects are in turn corrupted by both the measurement noise and the error in the estimated pose of the robot. That is, the error in robot's path correlates errors in the map. Hence the true map cannot be obtained without also reconstructing the path of the robot \textit{simultaneously}. 
	
	% There are a large number of algorithms to deal with this problem, such as Particle Filter based SLAM, \ekf based SLAM\cite{ekfSLAM1,ekfSLAM2,ekfSLAM3,ekfSLAM4}, Fast SLAM and several modifications of them. Each of them has it's own advantages and disadvantages based on the proprioceptive and exteroceptive sensors used, the kind of robot and the environment. For example, there are slam algorithms for robots equipped with a single camera\cite{mono1,mono2,mono3,mono4,mono5,mono6,mono7}, for those with a steroeo camera\cite{stereo1,stereo2,stereo3,stereo4,stereo5}, and different ones for sonar, for LIDAR and so forth.

%	
%	A common way to formulate the SLAM problem is that a executes controls and accumulates observations of it's environment, both corrupted by noise. The noisy readings can be modeled as probability distribution functions. Both the pose of the robot and the location of the environment objects can also be considered to be a probability distributions. Initially the variance of the robot pose is small, but it increases when it moves. The objects are assumed to have a large variance the first time they are seen, but with subsequent re-observation, the assurance of their position increases reducing the variance of it's probability distribution. 
%	
%	One of the algorithms used for SLAM makes use of the versatile Extended Kalman Filter. The major advantage of this algorithm is that it is very simple to implement on an on board computer and can be used for real time SLAM applications. The EKF based SLAM procedure involves first using proprioceptive sensors to get an estimate of our motion. This is called the \textit{Prediction} step. Then the exteroceptive sensors are used to get an idea of how our environment looks like. This is called \textit{Feature Extraction}. The features can be specific or generic.In subsequent time steps, the environmental features seen are compared to our previous idea of our environment and the difference is used to both improve the estimated position and the map of the surroundings. This is commonly referred to as the \textit{Correction} step. Each of these steps are described in section \ref{sec:EKF_SLAM}.
%	
%	Hence it is seen that, the SLAM algorithm consists of many sub parts each of which offer their own challenges and are again focused on the specific application. This lets SLAM research to be modular in nature. By making the base algorithm a simple one like EKF, different methods and algorithms can be plugged in for each of the subparts without disturbing the rest to give a good idea of their various advantages and disadvantages.
%	
%	For testing a basic algorithm like EKF, a classic experimental platform is used which is basically a differential drive ground vehicle. Specifically a six wheeled platform is used with the four exterior wheels being powered and the interior ones being used for odometry. The ground vehicle is also equipped with an autopilot including an Inertial Measurement Unit, an on board computer as well as exteroceptive sensors such as a 2D LIDAR and camera. The platform is further described in chapter \ref{cha:Platform}. With these features the platform is well equipped to try out SLAM algorithms. 
%	
%	Of all the various challenges in implementing SLAM, the subpart concentrated on in this thesis is the Feature Extraction. Features can either be identifiable as something specific or just robust generic features. Any exteroceptive sensor can be used either by itself or in conjunction with each other to extract features. Of the most common exteroceptive sensor used for SLAM is the LIDAR which gives us range data in either 2 or 3 dimensions. In the experimental platform mentioned above, the 2D LIDAR data is used to extract information about features already known to be in the environment such as cylinders placed there and walls.
%	
%	When initially trying to use the range data from the LIDAR, a simplistic algorithm is to use rapid changes of the range as features. While this is a simple algorithm used for trying out SLAM for the first time, it has several drawbacks which are subsequently explored. Also modifications for this algorithm are suggested and tried for making it more efficient. 
%	
%	A number of studies have shown that for indoor SLAM, which is the target environment in this thesis, linear features such as walls and doors are found to give much better results\cite{Garulli2005}. There are a variety of methods\cite{Nguyen2005} to find these linear features. To obtain a good understanding of how to extract these features a modification of the well known RANSAC algorithm \cite{Fischler1981} is implemented from scratch in python in section \ref{sec:ransac}. Another common method to extract linear features is the Hough transform which is claimed to give much better performance\cite{Hu1998}. Outside of understanding the method, for practical purposes it is usually advantageous to use optimized and parallelized implementations of the algorithms. So the LIDAR range data is rasterized into am image and the hough transform provided in the OPENCV library is used and walls are extracted from the LIDAR data in section \ref{sec:hough}. Both linear and point features are plugged into the feature detection of the EKF SLAM algorithm both individually and in combination and the results are presented in chapter \ref{cha:results}.



%In this thesis different algorithms to extract features from 2D scanning laser range data is studied in the light of their use for environment sensing in \slam(SLAM) applications. These algorithms are tested on a custom built platform dedicated for SLAM. In this chapter the motivation for SLAM along with some of the existing research in presented first. The next section introduces the importance of feature extraction in SLAM. The last section gives an overview of the rest of the thesis. 