\chapter{Introduction}

	Autonomous robots are growing increasingly popular in various fields. They occupy a major fraction of robotics based research today. Autonomous robots take many forms, from mobile robots to fixed manipulators. Even within mobile robots, the diversity in the type of locomotion, the terrain and the targeted use is huge. There are autonomous robots intended for indoor use, for rough terrains, for underwater and also aerial autonomous robots. 
	
	But irrespective of terrain, autonomous mobile robots all have one challenge in common. The ability to map their surroundings while simultaneously figuring out where exactly they are in that map. This concept of Simultaneous Localization and Mapping or SLAM is a vast field of research with numerous algorithms and implementations. Each of these algorithms, have their unique advantages and drawbacks making it impossible to pinpoint a generalized \textit{best algorithm}. 
	
	One of the algorithms used for SLAM is the Extended Kalman Filter. The major advantage of this algorithm is that it is very simple to implement on an on board computer and can be used for real time SLAM applications. Going a bit into EKF SLAM we first use the proprioceptive sensors to get an estimate of our motion. This is called the \textit{Prediction} step. Then we use the exteroceptive sensors to get and idea of how our environment looks like. We try to focus on specific features we know to look for or on generic features. This is called \textit{Feature Extraction}. In subsequent time steps, we compare the environmental features we see, to our previous idea of our environment and use the difference to both improve both our position estimate and our map of our surroundings. Which is the \textit{Correction} step. Hence we can see that, it consists of many sub parts within it which we shall discuss in depth at a later point. Each of these sub parts offer their own challenges and are again focused on the specific application. By making the base algorithm a simple one like EKF, we can plug in different methods and algorithms for each of the subparts without disturbing the rest to give a good idea of their various advantages and disadvantages. 
	
	For testing a basic algorithm like EKF, we use a classic experimental platform which is a differential drive ground vehicle. We use a six wheeled platform with the four exterior wheels being powered and the interior wheels being used for odometry. With this platform we try to map indoor environments such as corridors doors etc. The ground vehicle is also equipped with an autopilot including an Inertial Measurement Unit, an on board computer as well as exteroceptive sensors such as LIDAR and camera.
	
	Going into the subparts of SLAM, the first subpart concentrated on in this thesis is the Feature Extraction. Features can be identifiable features of robust generic features. Features can be extracted both from the camera and from the LIDAR. When dealing with the range data from the LIDAR, a simplistic algorithm is to use rapid changes of the range as features. While this is a simple algorithm used for trying out SLAM for the first time, it has several drawbacks which are subsequently explored. Also modifications for this algorithm are suggested and tried for making it more efficient. 
	
	A number of studies have shown that for indoor SLAM, which is the target environment in this thesis, linear features such as walls and doors are found to give much better results \cite{}. There are a variety of methods\cite{} to find these linear features. A few of them are implemented in python\cite{} and compared with respect to how effective they are for SLAM and their computation time.
	
	Once a good feature extractor which good results for EKF SLAM is implemented, the prediction subpart is analyzed. It essentially consists of using the odometry to get an estimate of the new position of the robot given it's old position. Initially when testing the other algorithms for feature extraction, a simple method of acquiring odometry was used. It was acquired through the encoders on the interior wheels of the mobile platform. Now, once a good feature extractor was implemented, there was scope to explore additional odometry methods such as visual odometry. Such a prediction which does not require the use of encoders, is really useful for application in a wide variety of platforms\cite{} where it is difficult to get odometry like in legged systems or aerial vehicles. 
	
	Once a good visual odometry system is implemented, we combine that with the linear feature extraction based correction to get a good SLAM implementation that is real time implementable. 
	
	
	

	
	